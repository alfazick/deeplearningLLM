{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTbRO8bzNCXz0ekoKJdojq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S2-fmiJ9cDB",
        "outputId": "350fcea1-77da-481f-afc9-4467b5741ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.5.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pAqZJTOT9uQ5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Steps of gradient descent\n",
        "\n",
        "# linear regression no activation function\n",
        "# y = wx + b + e\n"
      ],
      "metadata": {
        "id": "Q-jVOocs92rP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generation\n",
        "\n",
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = .1 * np.random.randn(N, 1)\n",
        "y = true_b + true_w * x + epsilon"
      ],
      "metadata": {
        "id": "ZRW-L9G4-nuE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting Data\n",
        "#shuffle\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "train_idx = idx[:int(0.8*N)]\n",
        "test_idx = idx[int(0.8*N):]"
      ],
      "metadata": {
        "id": "1pNij1xvUzwk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and validation\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[test_idx], y[test_idx]"
      ],
      "metadata": {
        "id": "HcuYfLo8U1PY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient descent\n",
        "# step 0 : random initialization\n",
        "b = np.random.randn(1)\n",
        "w = np.random.randn(1)\n",
        "print(b, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br6rQ8uvVbkG",
        "outputId": "678bb0e7-fccb-4cc6-f52a-6b036b9a0e47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.02514259] [0.18645431]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1 : Model prediction\n",
        "yhat = b + w * x_train"
      ],
      "metadata": {
        "id": "4Q3uobQ5Vr5L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step #2 : Compute the loss\n",
        "error = (yhat - y_train)\n",
        "\n",
        "loss = (error ** 2).mean()\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lA2fXfoV9i7",
        "outputId": "94c0adb0-c9cc-4916-d76b-7b12cdb79807"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.444680120636235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step #3 Compute the gradients\n",
        "b_grad = 2*error.mean()\n",
        "w_grad = 2*(x_train*error).mean()\n",
        "print(b_grad, w_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4htk2K7oWGpY",
        "outputId": "1cc6abe9-7dc5-4e85-e8fa-bc3eff3a4be1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7.781692427768675 -4.010835411595505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step #4 update the parameters\n",
        "lr = 0.1\n",
        "b = b - lr * b_grad\n",
        "w = w - lr * w_grad\n",
        "print(b, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTsgCBRdWYha",
        "outputId": "47c15ee7-cdfc-4244-89f1-f98b8cacb717"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.24697334] [0.58753786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rinse and repeat\n",
        "lr = 0.1\n",
        "epoch = 10000\n",
        "for epoch in range(epoch):\n",
        "    # predict forward pass\n",
        "    yhat = b + w * x_train\n",
        "    #mse loss\n",
        "    error = (yhat - y_train)\n",
        "    loss = (error ** 2).mean()\n",
        "    #calculate grad\n",
        "    b_grad = 2*error.mean()\n",
        "    w_grad = 2*(x_train*error).mean()\n",
        "    # update weights\n",
        "    b = b - lr * b_grad\n",
        "    w = w - lr * w_grad\n",
        "\n",
        "\n",
        "print(b, w)\n",
        "print(true_b, true_w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bder3tWWhu7",
        "outputId": "4aff5626-98cb-4003-e463-44a5e898797f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.02354075] [1.96896447]\n",
            "1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linr = LinearRegression()\n",
        "linr.fit(x_train,y_train)\n",
        "print(linr.intercept_,linr.coef_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xBGfbbbaQuL",
        "outputId": "8438e6f7-49ad-46e2-c511-5472353ff640"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.02354075] [1.96896447]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch Tensors\n",
        "scalar = torch.tensor(3.14)\n",
        "vector = torch.tensor([1,2,3])\n",
        "matrix = torch.ones((2,3),dtype = torch.float)\n",
        "tensor = torch.randn((2,3,4),dtype = torch.float)\n",
        "print(scalar)\n",
        "print(vector)\n",
        "print(matrix)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6bOwV4RadR0",
        "outputId": "509a9777-d137-47fe-ec91-c2100e597ceb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.1400)\n",
            "tensor([1, 2, 3])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[[-1.1097, -2.2141,  0.8423,  1.0552],\n",
            "         [-0.3254,  0.5537,  1.0209, -1.7730],\n",
            "         [ 1.1366, -1.6212,  0.1696,  1.0675]],\n",
            "\n",
            "        [[-1.1751, -0.6766, -1.0260,  2.7235],\n",
            "         [ 0.0332, -0.5168,  1.3203, -0.5577],\n",
            "         [ 0.2482, -0.6728, -0.1930, -0.4676]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pOX11G5tn9x",
        "outputId": "ab883d3d-569f-471d-a585-3698fbefb76f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ6LmhjktvJo",
        "outputId": "5a6b27f7-a4c6-48ec-e2cc-95bca73de5d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch4kIS4FtwiQ",
        "outputId": "864adeba-6c6a-40e4-8b18-b20e0d14fc5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCpgAA8lt3bK",
        "outputId": "1db5e366-5eb3-4408-ffa0-66839e95842b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same_matrix = matrix.view(1,6)"
      ],
      "metadata": {
        "id": "dr0oGRLft5_r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same_matrix[0,1] = 2"
      ],
      "metadata": {
        "id": "Unvo6B9FuFlx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(matrix)\n",
        "print(same_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "745eVwLguIvx",
        "outputId": "54f6eb8c-af8d-479b-9d43-94ca62905b9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 2., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "different_matrix = matrix.new_tensor(matrix.view(1,6))\n",
        "different_matrix[0,1] = 3.\n",
        "print(matrix)\n",
        "print(different_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF9zjC3JuLRi",
        "outputId": "6ba35a5e-5297-4274-b9c3-a8ab1d86e0f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 3., 1., 1., 1., 1.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-7c0a75bcd1f3>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  different_matrix = matrix.new_tensor(matrix.view(1,6))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "another_matrix = matrix.view(1,6).clone().detach()\n",
        "another_matrix[0,1] = 4.\n",
        "print(matrix)\n",
        "print(another_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-o2keyVuWvW",
        "outputId": "da3f3587-f08e-428a-fa31-8ccfcdee9f15"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 4., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "print(x_train_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr1M6lU1umfc",
        "outputId": "01d42458-31df-442f-93a8-f57ed8909c3b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_tensor = x_train_tensor.to(torch.float)\n",
        "print(float_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTmIc_sCDRHs",
        "outputId": "6682a7d6-1bac-4c5b-b81e-ef9b822f58bc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(float_tensor.numpy()[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeEJcOWqDWfH",
        "outputId": "02a638af-49cf-4c5a-afbd-bf8a1bc1b885"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.77127033]\n",
            " [0.06355835]\n",
            " [0.86310345]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cheching if device has GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqMGULuNDhkR",
        "outputId": "6f406f72-f8ca-40aa-eace-6b70d8ae1af5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_cudas = torch.cuda.device_count()\n",
        "for i in range(n_cudas):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "metadata": {
        "id": "EwTWJQFzD9lg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_tensor = float_tensor.to(device)\n",
        "print(gpu_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP4A_20GEEf_",
        "outputId": "8d43dbb6-d554-47d6-b582-323481563678"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7713])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting GPU tensor to cpu first and then to numpy\n",
        "back_to_numpy = x_train_tensor.cpu().numpy()\n",
        "print(back_to_numpy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izfalw3VEKM4",
        "outputId": "f6b32505-f49d-4f88-d8c2-330da8e73c66"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating parameters, tensors\n",
        "# first send tensor to device and then use the requires_grad()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "b = torch.randn(1).to(device)\n",
        "w = torch.randn(1).to(device)\n",
        "print(b, w)\n",
        "\n",
        "b.requires_grad_()\n",
        "w.requires_grad_()\n",
        "print(b, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWeF-rcUEeI-",
        "outputId": "59d83b45-5fe0-43bd-9240-f9d71fc74049"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6828]) tensor([1.9209])\n",
            "tensor([-0.6828], requires_grad=True) tensor([1.9209], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randn(1, requires_grad = True,dtype=torch.float,device=device)\n",
        "w = torch.randn(1, requires_grad = True,dtype=torch.float,device=device)\n",
        "print(b, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDBau2KNFfci",
        "outputId": "1f2c1a36-7b5f-4b68-bb9b-445aca839347"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2398], requires_grad=True) tensor([1.4581], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign tensors to a device at the moment of its creation to avoid unexpected behaviors"
      ],
      "metadata": {
        "id": "TYWB1mMSF0Aj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def train_step(x_train, y_train, w, b, device='cpu'):\n",
        "    \"\"\"\n",
        "    Performs one training step for linear regression using PyTorch autograd\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    x_train : numpy.ndarray\n",
        "        Input training data\n",
        "    y_train : numpy.ndarray\n",
        "        Target training data\n",
        "    w : torch.Tensor\n",
        "        Weight parameter with requires_grad=True\n",
        "    b : torch.Tensor\n",
        "        Bias parameter with requires_grad=True\n",
        "    device : str\n",
        "        Device to run computations on ('cpu' or 'cuda')\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    loss : torch.Tensor\n",
        "        Mean squared error loss\n",
        "    yhat : torch.Tensor\n",
        "        Model predictions\n",
        "    \"\"\"\n",
        "    # Convert numpy arrays to PyTorch tensors and move to specified device\n",
        "    x_train_tensor = torch.as_tensor(x_train, dtype=torch.float32).to(device)\n",
        "    y_train_tensor = torch.as_tensor(y_train, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Step 1: Compute model predictions (forward pass)\n",
        "    yhat = b + w * x_train_tensor\n",
        "\n",
        "    # Step 2: Compute loss (MSE)\n",
        "    error = yhat - y_train_tensor\n",
        "    loss = torch.mean(error ** 2)\n",
        "\n",
        "    # Step 3: Compute gradients (backward pass)\n",
        "    loss.backward()\n",
        "\n",
        "    return loss, yhat\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate sample data\n",
        "    np.random.seed(42)\n",
        "    x_train = np.random.rand(100, 1)\n",
        "    y_train = 2 * x_train + 1 + np.random.randn(100, 1) * 0.1\n",
        "\n",
        "    # Initialize parameters with requires_grad=True\n",
        "    w = torch.tensor(0.0, requires_grad=True)\n",
        "    b = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "    # Perform one training step\n",
        "    loss, predictions = train_step(x_train, y_train, w, b)\n",
        "\n",
        "    print(f\"Loss: {loss.item():.4f}\")\n",
        "    print(f\"Weight gradient: {w.grad.item():.4f}\")\n",
        "    print(f\"Bias gradient: {b.grad.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGYtVROQGCR-",
        "outputId": "b10c91a4-69cf-40e4-c46f-14ce3581b872"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.1072\n",
            "Weight gradient: -2.1669\n",
            "Bias gradient: -3.8805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient accumulation\n",
        "# This code will be placed _after_ step 4\n",
        "# (updating the parameters)\n",
        "print(b.grad.zero_(), w.grad.zero_())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wpK0hsRzYPG",
        "outputId": "5a0ab958-b5e9-46cb-dbae-34999185a9eb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.) tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating Parameters\n",
        "# Let's break down this PyTorch gradient descent implementation\n",
        "\n",
        "# 1. Setup and Initialization\n",
        "lr = 0.1  # Learning rate\n",
        "torch.manual_seed(42)  # Set random seed for reproducibility\n",
        "\n",
        "# Initialize parameters with random values and enable gradient tracking\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)  # bias\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)  # weight\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs):\n",
        "    # Forward pass\n",
        "    yhat = b + w * x_train_tensor  # Linear model: y = wx + b\n",
        "    error = (yhat - y_train_tensor)  # Calculate error\n",
        "    loss = (error ** 2).mean()  # Mean squared error loss\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()  # Compute gradients\n",
        "\n",
        "    # Parameter updates using gradient descent\n",
        "    with torch.no_grad():  # Temporarily disable gradient tracking\n",
        "        b -= lr * b.grad  # Update bias: b = b - lr * gradient\n",
        "        w -= lr * w.grad  # Update weight: w = w - lr * gradient\n",
        "\n",
        "    # Reset gradients to zero\n",
        "    b.grad.zero_()  # Clear bias gradient\n",
        "    w.grad.zero_()  # Clear weight gradient\n",
        "\n",
        "print(b, w)  # Print final parameters\n",
        "\n",
        "\"\"\"\n",
        "Key Concepts Explained:\n",
        "\n",
        "1. requires_grad=True\n",
        "   - This tells PyTorch to track operations on these tensors\n",
        "   - Enables automatic differentiation\n",
        "   - Creates computational graph for backpropagation\n",
        "\n",
        "2. loss.backward()\n",
        "   - Computes gradients for all tensors with requires_grad=True\n",
        "   - Uses chain rule to calculate derivatives\n",
        "   - Stores gradients in .grad attribute of tensors\n",
        "\n",
        "3. with torch.no_grad():\n",
        "   - Temporarily disables gradient computation\n",
        "   - Necessary for parameter updates to prevent tracking\n",
        "   - Without this, PyTorch would try to build a computational graph for the updates\n",
        "   - Would lead to incorrect gradients and higher memory usage\n",
        "\n",
        "4. Why zero_grad() is necessary:\n",
        "   - PyTorch accumulates gradients by default\n",
        "   - Without zeroing, gradients from previous steps would be added\n",
        "   - Must reset before next forward/backward pass\n",
        "   - Alternative: optimizer.zero_grad() if using PyTorch optimizer\n",
        "\n",
        "Common Pitfalls to Avoid:\n",
        "1. Forgetting torch.no_grad() for updates\n",
        "2. Not zeroing gradients between iterations\n",
        "3. Using inplace operations without care\n",
        "4. Not handling GPU/CPU device placement consistently\n",
        "\n",
        "Best Practices:\n",
        "1. Always use torch.no_grad() for parameter updates\n",
        "2. Clear gradients after each iteration\n",
        "3. Set random seed for reproducibility\n",
        "4. Use appropriate data types and devices\n",
        "5. Consider using PyTorch's built-in optimizers for production code\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "FSJlhwaw0s1G",
        "outputId": "b33d6589-c559-4d84-c603-0bade22c84de"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nKey Concepts Explained:\\n\\n1. requires_grad=True\\n   - This tells PyTorch to track operations on these tensors\\n   - Enables automatic differentiation\\n   - Creates computational graph for backpropagation\\n\\n2. loss.backward()\\n   - Computes gradients for all tensors with requires_grad=True\\n   - Uses chain rule to calculate derivatives\\n   - Stores gradients in .grad attribute of tensors\\n\\n3. with torch.no_grad():\\n   - Temporarily disables gradient computation\\n   - Necessary for parameter updates to prevent tracking\\n   - Without this, PyTorch would try to build a computational graph for the updates\\n   - Would lead to incorrect gradients and higher memory usage\\n\\n4. Why zero_grad() is necessary:\\n   - PyTorch accumulates gradients by default\\n   - Without zeroing, gradients from previous steps would be added\\n   - Must reset before next forward/backward pass\\n   - Alternative: optimizer.zero_grad() if using PyTorch optimizer\\n\\nCommon Pitfalls to Avoid:\\n1. Forgetting torch.no_grad() for updates\\n2. Not zeroing gradients between iterations\\n3. Using inplace operations without care\\n4. Not handling GPU/CPU device placement consistently\\n\\nBest Practices:\\n1. Always use torch.no_grad() for parameter updates\\n2. Clear gradients after each iteration\\n3. Set random seed for reproducibility\\n4. Use appropriate data types and devices\\n5. Consider using PyTorch's built-in optimizers for production code\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T34rcr751voY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}